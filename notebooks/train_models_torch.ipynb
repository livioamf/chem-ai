{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f577a7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path configurado para importar módulos de 'chemai':\n",
      "c:\\Users\\f0pi\\git\\viscosidade-ai\n",
      "Proxy configurado.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n",
    "\n",
    "print(\"Path configurado para importar módulos de 'chemai':\")\n",
    "print(ROOT_DIR)\n",
    "\n",
    "\n",
    "from proxy import configure_proxy\n",
    "configure_proxy(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8d7c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "from chemai.loader import DipprDatasetLoader\n",
    "from chemai.train import train_test_split\n",
    "from chemai.model import ChemBERTModel\n",
    "from chemai.datamodule import ChemBERTDataModule\n",
    "from chemai.callbacks import BestModelExporter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7df9100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /DeepChem/ChemBERTa-77M-MTR/resolve/main/tokenizer_config.json (Caused by ProxyError(\\'Unable to connect to proxy\\', NameResolutionError(\"HTTPSConnection(host=\\'inet-sys.petrobras.com.br\\', port=804): Failed to resolve \\'inet-sys.petrobras.com.br\\' ([Errno 11001] getaddrinfo failed)\")))'), '(Request ID: 81b93c28-204e-463e-970f-3eac968c91c1)')' thrown while requesting HEAD https://huggingface.co/DeepChem/ChemBERTa-77M-MTR/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /DeepChem/ChemBERTa-77M-MTR/resolve/main/tokenizer_config.json (Caused by ProxyError(\\'Unable to connect to proxy\\', NameResolutionError(\"HTTPSConnection(host=\\'inet-sys.petrobras.com.br\\', port=804): Failed to resolve \\'inet-sys.petrobras.com.br\\' ([Errno 11001] getaddrinfo failed)\")))'), '(Request ID: 5f6037ee-a597-4b28-8448-f6186063fe09)')' thrown while requesting HEAD https://huggingface.co/DeepChem/ChemBERTa-77M-MTR/resolve/main/tokenizer_config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /DeepChem/ChemBERTa-77M-MTR/resolve/main/tokenizer_config.json (Caused by ProxyError(\\'Unable to connect to proxy\\', NameResolutionError(\"HTTPSConnection(host=\\'inet-sys.petrobras.com.br\\', port=804): Failed to resolve \\'inet-sys.petrobras.com.br\\' ([Errno 11001] getaddrinfo failed)\")))'), '(Request ID: ea47147d-b19f-45a5-99ab-fc369b8496c2)')' thrown while requesting HEAD https://huggingface.co/DeepChem/ChemBERTa-77M-MTR/resolve/main/tokenizer_config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /DeepChem/ChemBERTa-77M-MTR/resolve/main/tokenizer_config.json (Caused by ProxyError(\\'Unable to connect to proxy\\', NameResolutionError(\"HTTPSConnection(host=\\'inet-sys.petrobras.com.br\\', port=804): Failed to resolve \\'inet-sys.petrobras.com.br\\' ([Errno 11001] getaddrinfo failed)\")))'), '(Request ID: 7559c203-cec0-49c5-96ad-9185527c8547)')' thrown while requesting HEAD https://huggingface.co/DeepChem/ChemBERTa-77M-MTR/resolve/main/tokenizer_config.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /DeepChem/ChemBERTa-77M-MTR/resolve/main/tokenizer_config.json (Caused by ProxyError(\\'Unable to connect to proxy\\', NameResolutionError(\"HTTPSConnection(host=\\'inet-sys.petrobras.com.br\\', port=804): Failed to resolve \\'inet-sys.petrobras.com.br\\' ([Errno 11001] getaddrinfo failed)\")))'), '(Request ID: 26b5e1f3-f3a3-42bf-b41f-2c4950bf7ec7)')' thrown while requesting HEAD https://huggingface.co/DeepChem/ChemBERTa-77M-MTR/resolve/main/tokenizer_config.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /DeepChem/ChemBERTa-77M-MTR/resolve/main/tokenizer_config.json (Caused by ProxyError(\\'Unable to connect to proxy\\', NameResolutionError(\"HTTPSConnection(host=\\'inet-sys.petrobras.com.br\\', port=804): Failed to resolve \\'inet-sys.petrobras.com.br\\' ([Errno 11001] getaddrinfo failed)\")))'), '(Request ID: edf93934-df91-44f1-92f2-f42e799aedbf)')' thrown while requesting HEAD https://huggingface.co/DeepChem/ChemBERTa-77M-MTR/resolve/main/tokenizer_config.json\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /DeepChem/ChemBERTa-77M-MTR/resolve/main/config.json (Caused by ProxyError(\\'Unable to connect to proxy\\', NameResolutionError(\"HTTPSConnection(host=\\'inet-sys.petrobras.com.br\\', port=804): Failed to resolve \\'inet-sys.petrobras.com.br\\' ([Errno 11001] getaddrinfo failed)\")))'), '(Request ID: ee9e90da-0473-4ffc-bf7a-249576fbb551)')' thrown while requesting HEAD https://huggingface.co/DeepChem/ChemBERTa-77M-MTR/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"DeepChem/ChemBERTa-77M-MTR\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "base_model = AutoModel.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43133a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 13\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_SEED = 13\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "random.seed(GLOBAL_SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(GLOBAL_SEED)\n",
    "\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "torch.cuda.manual_seed_all(GLOBAL_SEED)\n",
    "pl.seed_everything(GLOBAL_SEED, workers=True)\n",
    "torch.use_deterministic_algorithms(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4d723a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puro: train=5268, dev=1450, test=885\n",
      "Mix: train=20635, dev=5254, test=5585\n"
     ]
    }
   ],
   "source": [
    "data_loader = DipprDatasetLoader(data_dir='../data/nist_dippr_data')\n",
    "data_loader.prepare()\n",
    "pure = data_loader.get_pure()\n",
    "mix = data_loader.get_mix()\n",
    "pure_train, pure_dev = train_test_split(\n",
    "    smiles1=pure['train'][\"MOL\"].to_list(), \n",
    "    temperatures=pure['train'][\"T\"].values, \n",
    "    y=pure['train'][\"logV\"].values\n",
    ")\n",
    "pure_test = {\n",
    "    'smiles': pure['test'][\"MOL\"].to_list(),\n",
    "    'temperatures': pure['test'][\"T\"].values,\n",
    "    'y':  pure['test'][\"logV\"].values\n",
    "}\n",
    "\n",
    "mix_train, mix_dev = train_test_split(\n",
    "    smiles1=mix['train'][\"MOL_1\"].to_list(),\n",
    "    smiles2=mix['train'][\"MOL_2\"].to_list(),\n",
    "    frac=mix['train'][\"MolFrac_1\"].values,\n",
    "    temperatures=mix['train'][\"T\"].values,\n",
    "    y=mix['train'][\"logV\"].values,\n",
    ")\n",
    "mix_test = {\n",
    "    \"smiles_1\": mix['test'][\"MOL_1\"].to_list(),\n",
    "    \"smiles_2\": mix['test'][\"MOL_2\"].to_list(),\n",
    "    \"frac\": mix['test'][\"MolFrac_1\"].values,\n",
    "    \"temperatures\": mix['test'][\"T\"].values,\n",
    "    \"y\": mix['test'][\"logV\"].values,\n",
    "}\n",
    "\n",
    "print(f\"Puro: train={len(pure_train['temperatures'])}, dev={len(pure_dev['temperatures'])}, test={len(pure_test['temperatures'])}\")\n",
    "print(f\"Mix: train={len(mix_train['temperatures'])}, dev={len(mix_dev['temperatures'])}, test={len(mix_test['temperatures'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbd80e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_pure = StandardScaler()\n",
    "pure_train['temperatures'] = scaler_pure.fit_transform(pure_train['temperatures'].reshape(-1, 1)).reshape(-1)\n",
    "pure_dev['temperatures'] = scaler_pure.transform(pure_dev['temperatures'].reshape(-1, 1)).reshape(-1)\n",
    "pure_test['temperatures'] = scaler_pure.transform(pure_test['temperatures'].reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "scaler_mix = StandardScaler()\n",
    "mix_train['temperatures'] = scaler_mix.fit_transform(mix_train['temperatures'].reshape(-1, 1)).reshape(-1)\n",
    "mix_dev['temperatures'] = scaler_mix.transform(mix_dev['temperatures'].reshape(-1, 1)).reshape(-1)\n",
    "mix_test['temperatures'] = scaler_mix.transform(mix_test['temperatures'].reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e22d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_dm = ChemBERTDataModule(tokenizer, pure_train, pure_dev, pure_test, batch_size=64, max_length=35)\n",
    "mix_dm = ChemBERTDataModule(tokenizer, mix_train, mix_dev, mix_test, batch_size=64, max_length=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2f4bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_variant(mode, use_lora, datamodule, export_dir='../models/torch'):\n",
    "    if use_lora:\n",
    "        lora_cfg = LoraConfig(r=8, lora_alpha=16, lora_dropout=0.1, task_type=\"FEATURE_EXTRACTION\")\n",
    "        model_base = get_peft_model(base_model, lora_cfg)\n",
    "    else:\n",
    "        model_base = base_model\n",
    "\n",
    "    model = ChemBERTModel(\n",
    "        base_model=model_base,\n",
    "        mode=mode,\n",
    "        hidden_dim=128,\n",
    "        lr_head=1e-3,\n",
    "        lr_lora=2e-4,\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "\n",
    "    ckpt = ModelCheckpoint(monitor=\"val_r2\", save_top_k=1, mode=\"max\")\n",
    "    early = EarlyStopping(monitor=\"val_r2\", patience=5, mode=\"max\")\n",
    "\n",
    "    scaler = scaler_pure if mode == 'pure' else scaler_mix\n",
    "    exporter = BestModelExporter(export_dir=\n",
    "                                 f\"{export_dir}/{mode}_{'lora' if use_lora else 'base'}\", \n",
    "                                 scaler=scaler\n",
    "    )\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=100,\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        callbacks=[ckpt, early, exporter],\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2df1e5f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model congelado (train apenas MLP).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "c:\\Users\\f0pi\\AppData\\Local\\miniforge3\\envs\\chemai\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type         </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ base_model │ RobertaModel │  3.4 M │ eval  │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ mlp        │ Sequential   │ 49.5 K │ train │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ train_r2   │ R2Score      │      0 │ train │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ val_r2     │ R2Score      │      0 │ train │     0 │\n",
       "└───┴────────────┴──────────────┴────────┴───────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType        \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ base_model │ RobertaModel │  3.4 M │ eval  │     0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ mlp        │ Sequential   │ 49.5 K │ train │     0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ train_r2   │ R2Score      │      0 │ train │     0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ val_r2     │ R2Score      │      0 │ train │     0 │\n",
       "└───┴────────────┴──────────────┴────────┴───────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 49.5 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 3.4 M                                                                                        \n",
       "<span style=\"font-weight: bold\">Total params</span>: 3.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 13                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 7                                                                                           \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 66                                                                                           \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 49.5 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 3.4 M                                                                                        \n",
       "\u001b[1mTotal params\u001b[0m: 3.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 13                                                                         \n",
       "\u001b[1mModules in train mode\u001b[0m: 7                                                                                           \n",
       "\u001b[1mModules in eval mode\u001b[0m: 66                                                                                           \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e95a0ec66e42c8b7bf113d44348b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\f0pi\\AppData\\Local\\miniforge3\\envs\\chemai\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_conn\n",
       "ector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the \n",
       "value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\f0pi\\AppData\\Local\\miniforge3\\envs\\chemai\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_conn\n",
       "ector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the \n",
       "value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\f0pi\\AppData\\Local\\miniforge3\\envs\\chemai\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_conn\n",
       "ector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the \n",
       "value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\f0pi\\AppData\\Local\\miniforge3\\envs\\chemai\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_conn\n",
       "ector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the \n",
       "value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\f0pi\\AppData\\Local\\miniforge3\\envs\\chemai\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:534: Found\n",
       "66 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this \n",
       "is intentional, you can ignore this warning.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\f0pi\\AppData\\Local\\miniforge3\\envs\\chemai\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:534: Found\n",
       "66 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this \n",
       "is intentional, you can ignore this warning.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">[Exporter] Recarregando melhor checkpoint: \n",
       "c:\\Users\\f0pi\\git\\viscosidade-ai\\notebooks\\lightning_logs\\version_4\\checkpoints\\epoch=11-step=996.ckpt\n",
       "</pre>\n"
      ],
      "text/plain": [
       "[Exporter] Recarregando melhor checkpoint: \n",
       "c:\\Users\\f0pi\\git\\viscosidade-ai\\notebooks\\lightning_logs\\version_4\\checkpoints\\epoch=11-step=996.ckpt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Base model congelado (train apenas MLP).\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Base model congelado (train apenas MLP).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">[Exporter] Modelo não é LoRA/PEFT, não será salvo.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "[Exporter] Modelo não é LoRA/PEFT, não será salvo.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">[Exporter] MLP salva em mlp.pt\n",
       "</pre>\n"
      ],
      "text/plain": [
       "[Exporter] MLP salva em mlp.pt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">[Exporter] Scaler salvo em scaler.json (manual).\n",
       "</pre>\n"
      ],
      "text/plain": [
       "[Exporter] Scaler salvo em scaler.json (manual).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">[Exporter] Exportação concluída com sucesso.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "[Exporter] Exportação concluída com sucesso.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_variant('pure', False, pure_dm)\n",
    "# train_variant('pure', True, pure_dm)\n",
    "# train_variant('mix', False, mix_dm)\n",
    "# train_variant('mix', True, mix_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e539805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_torch_pipeline(mode, model_dir, test_loader, max_length=128):\n",
    "    map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    mlp = torch.load(f\"{model_dir}/mlp.pt\", map_location=map_location, weights_only=False)\n",
    "    mlp.eval().to(map_location)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    base_model = AutoModel.from_pretrained(model_dir)\n",
    "    base_model.to(map_location).eval()\n",
    "\n",
    "    reals, preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            out1 = base_model(\n",
    "                input_ids=batch['input_ids_1'].to(map_location),\n",
    "                attention_mask=batch['attention_mask_1'].to(map_location),\n",
    "            )\n",
    "            cls1 = out1.last_hidden_state[:, 0, :]\n",
    "    \n",
    "            if mode == 'pure':\n",
    "                t = batch['temperatures'].unsqueeze(1).to(map_location).float()\n",
    "                x = torch.cat([cls1, t], dim=1)\n",
    "                y_hat = mlp(x).squeeze(1)\n",
    "            else:\n",
    "                out2 = base_model(\n",
    "                    input_ids=batch['input_ids_2'].to(map_location),\n",
    "                    attention_mask=batch['attention_mask_2'].to(map_location),\n",
    "                )\n",
    "                \n",
    "                cls2 = out2.last_hidden_state[:, 0, :]\n",
    "                t = batch['temperatures'].unsqueeze(1).to(map_location).float()\n",
    "                f = batch['frac'].unsqueeze(1).to(map_location).float()\n",
    "        \n",
    "                x1 = torch.cat([cls1, cls2, t, f], dim=1)\n",
    "                x2 = torch.cat([cls2, cls1, t, 1 - f], dim=1)\n",
    "                y_hat = 0.5 * (mlp(x1) + mlp(x2))\n",
    "                \n",
    "            reals.append(batch[\"y\"])\n",
    "            preds.append(y_hat.cpu())\n",
    "\n",
    "    reals = torch.cat(reals)\n",
    "    preds = torch.cat(preds)\n",
    "\n",
    "    r2 = r2_score(reals, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(reals, preds))\n",
    "\n",
    "    return {\"Model_Dir\": model_dir, \"R2\": r2, \"RMSE\": rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd961c86-411a-4509-a0fc-637805ebdfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset Arquitetura        R2      RMSE\n",
      "0     mix        base  0.937714  0.089623\n",
      "1     mix        lora  0.932687  0.093170\n",
      "2    pure        base  0.934206  0.109539\n",
      "3    pure        lora  0.947874  0.097499\n"
     ]
    }
   ],
   "source": [
    "def evaluate_all_models(base_dir=\"../models/torch\", max_length=35):\n",
    "    pure_dm.setup('test')\n",
    "    mix_dm.setup('test')\n",
    "    \n",
    "    configs = [\n",
    "        (\"pure_base\", pure_dm.test_dataloader()),\n",
    "        (\"pure_lora\", pure_dm.test_dataloader()),\n",
    "        (\"mix_base\", mix_dm.test_dataloader()),\n",
    "        (\"mix_lora\", mix_dm.test_dataloader())\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for model_name, test_dataloader in configs:\n",
    "        model_dir = f\"{base_dir}/{model_name}\"\n",
    "        parts = model_name.split('_')\n",
    "        res = evaluate_torch_pipeline(parts[0], model_dir, test_dataloader, max_length)\n",
    "        results.append({\n",
    "            \"Dataset\": parts[0],\n",
    "            \"Arquitetura\": parts[1],\n",
    "            \"R2\": res[\"R2\"],\n",
    "            \"RMSE\": res[\"RMSE\"]\n",
    "        })\n",
    "\n",
    "    df_results = pd.DataFrame(results).sort_values(by=[\"Dataset\", \"Arquitetura\"]).reset_index(drop=True)\n",
    "    return df_results\n",
    "\n",
    "\n",
    "metrics_all_df = evaluate_all_models()\n",
    "print(metrics_all_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06d39b7f-756c-457e-b465-f38b4ee61195",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all_df\n",
    "metrics_all_df.index.name =  'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2589094-d267-498f-b24a-8fd7062aee80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Arquitetura</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mix</td>\n",
       "      <td>base</td>\n",
       "      <td>0.937714</td>\n",
       "      <td>0.089623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mix</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.932687</td>\n",
       "      <td>0.093170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pure</td>\n",
       "      <td>base</td>\n",
       "      <td>0.934206</td>\n",
       "      <td>0.109539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pure</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.947874</td>\n",
       "      <td>0.097499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset Arquitetura        R2      RMSE\n",
       "id                                        \n",
       "0      mix        base  0.937714  0.089623\n",
       "1      mix        lora  0.932687  0.093170\n",
       "2     pure        base  0.934206  0.109539\n",
       "3     pure        lora  0.947874  0.097499"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd626a27-98c8-4687-bc6c-77ac38068fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "293cf33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_dict = {\n",
    "    'mean_': scaler.mean_.tolist() if hasattr(scaler, 'mean_') else None,\n",
    "    'scale_': scaler.scale_.tolist() if hasattr(scaler, 'scale_') else None,\n",
    "    'var_': scaler.var_.tolist() if hasattr(scaler, 'var_') else None,\n",
    "    'n_features_in_': getattr(scaler, 'n_features_in_', None),\n",
    "    'feature_names_in_': getattr(scaler, 'feature_names_in_', None),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5124031f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_': None,\n",
       " 'scale_': None,\n",
       " 'var_': None,\n",
       " 'n_features_in_': None,\n",
       " 'feature_names_in_': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cc75fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\f0pi\\\\git'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(os.path.join(os.getcwd(), '..', '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2756c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\f0pi\\\\git\\\\viscosidade-ai\\\\notebooks'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8542ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
